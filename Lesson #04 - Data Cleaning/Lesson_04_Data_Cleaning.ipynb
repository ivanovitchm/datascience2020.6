{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lesson #04 - Data Cleaning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTb4JhPs2iv5"
      },
      "source": [
        "## 1 Working with Strings in Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoMcCvtJ3CLp"
      },
      "source": [
        "### 1.1 Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN3CQqQM3EPh"
      },
      "source": [
        "In the previous lesson, we learned how to use the **apply()**, **map()**, and **applymap()** methods to apply a function to a series. While we could certainly use these methods to clean strings in columns, pandas has built in many vectorized string methods that can perform these tasks quicker and with less keystrokes.\n",
        "\n",
        "We introduced some of these methods already in the Lesson #03 when we learned the following data cleaning tasks:\n",
        "\n",
        "- Cleaning column names\n",
        "- Extracting values from the start of strings\n",
        "- Extracting values from the end of strings\n",
        "\n",
        "In this lesson, we'll learn a couple other string cleaning tasks such as:\n",
        "\n",
        "- Finding specific strings or substrings in columns\n",
        "- Extracting substrings from unstructured data\n",
        "- Removing strings or substrings from a series\n",
        "\n",
        "As we learn these tasks, we'll also work to build intuition around how these string methods operate so that you can explore methods we haven't explicitly covered on your own.\n",
        "\n",
        "We'll work with the 2015 World Happiness Report again and additional economic data from the World Bank. You can find the data set [here](https://www.kaggle.com/worldbank/world-development-indicators/version/2). Here's a preview of the data set:\n",
        "\n",
        "\n",
        "| | CountryCode | ShortName | CurrencyUnit | Region | IncomeGroup | SpecialNotes | SourceOfMostRecentIncomeAndExpenditureData |  \n",
        "|-------------|-----------|----------------|----------------|----------------------------|----------------------|-----------------|---------------------------------------------------|\n",
        "| 0 | AFG | Afghanistan | Afghan afghani | South Asia | Low income | Fiscal year end... | Integrated household survey (IHS), 2008 |\n",
        "| 1 | ALB | Albania | Albanian lek | Europe & Central Asia | Upper middle income | NaN | Living Standards Measurement Study Survey (LSM... |\n",
        "| 2 | DZA | Algeria | Algerian dinar | Middle East & North Africa | Upper middle income | NaN | Integrated household survey (IHS), 1995 |\n",
        "| 3 | ASM | American Samoa | U.S. dollar | East Asia & Pacific | Upper middle income | NaN | NaN |\n",
        "| 4 | ADO | Andorra | Euro | Europe & Central Asia | High income: nonOECD | NaN | NaN |\n",
        "\n",
        "\n",
        "Below are descriptions for the columns we'll be working with:\n",
        "\n",
        "- **ShortName** - Name of the country\n",
        "- **Region** - The region the country belongs to\n",
        "- **IncomeGroup** - The income group the country belongs to, based on Gross National Income (GNI) per capita\n",
        "- **CurrencyUnit** - Name of country's currency\n",
        "- **SourceOfMostRecentIncomeAndExpenditureData** - The name of the survey used to collect the income and expenditure data\n",
        "- **SpecialNotes** - Contains any miscellaneous notes about the data\n",
        "\n",
        "To start, let's read the data sets into pandas and combine them.\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "\n",
        "We've already read **World_Happiness_2015.csv** into a dataframe called **happiness2015** and **World_dev.csv** into a dataframe called **world_dev**.\n",
        "\n",
        "- Use the **pd.merge()** function to combine **happiness2015** and **world_dev**. Save the resulting dataframe to **merged**. As a reminder, you can use the following syntax to combine the dataframes: \n",
        "```python\n",
        "pd.merge(left=df1, right=df2, how='left', left_on='left_df_Column_Name', right_on='right_df_Column_Name')\n",
        "```\n",
        "  - Set the **left_on** parameter to the **Country** column from **happiness2015** and the **right_on** parameter to the **ShortName** column from **world_dev**.\n",
        "- Use the **DataFrame.rename()** method to rename the **SourceOfMostRecentIncomeAndExpenditureData** column in **merged** to **IESurvey** (because we don't want to keep typing that long name!).\n",
        "  - We've already saved the mapping to a dictionary named **col_renaming**.\n",
        "  - Make sure to set the **axis** parameter to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raGLAdcE3fq3"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "happiness2015 = pd.read_csv(\"World_Happiness_2015.csv\")\n",
        "world_dev = pd.read_csv(\"World_dev.csv\")\n",
        "col_renaming = {'SourceOfMostRecentIncomeAndExpenditureData': 'IESurvey'}\n",
        "\n",
        "# put your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1b031lP7DTA"
      },
      "source": [
        "### 1.2 Using Apply to Transform Strings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03oT3S5Q8fCJ"
      },
      "source": [
        "In the last section, we combined **happiness2015** and **world_dev** and assigned the result to **merged**. Below are the first five rows of **merged** (after removing some of the columns we don't need):\n",
        "\n",
        "\n",
        "| |Country | Happiness Rank | Happiness Score | CountryCode | ShortName | CurrencyUnit | IncomeGroup | SpecialNotes | IESurvey |  \n",
        "|---------|----------------|-----------------|-------------|-----------|--------------|-----------------|-------------------|---------------------------------------------------|------------------------------------------------|\n",
        "| 0 | Switzerland | 1 | 7.587 | CHE | Switzerland | Swiss franc | High income: OECD | NaN | Expenditure survey/budget survey (ES/BS), 2004 |\n",
        "| 1 | Iceland | 2 | 7.561 | ISL | Iceland | Iceland krona | High income: OECD | NaN | Integrated household survey (IHS), 2010 |\n",
        "| 2 | Denmark | 3 | 7.527 | DNK | Denmark | Danish krone | High income: OECD | NaN | Income tax registers (ITR), 2010 |\n",
        "| 3 | Norway | 4 | 7.522 | NOR | Norway | Norwegian krone | High income: OECD | NaN | Income survey (IS), 2010 |\n",
        "| 4 | Canada | 5 | 7.427 | CAN | Canada | Canadian dollar | High income: OECD | Fiscal year end... | Labor force survey (LFS), 2010 |\n",
        "\n",
        "Let's work with the **CurrencyUnit** column first. Suppose we wanted to extract the unit of currency without the leading nationality. For example, instead of \"Danish krone\" or \"Norwegian krone\", we just needed \"krone\".\n",
        "\n",
        "If we wanted to complete this task for just one of the strings, we could use Python's [string.split()](https://docs.python.org/3/library/stdtypes.html) method:\n",
        "\n",
        "```python\n",
        "words = 'Danish krone'\n",
        "\n",
        "#Use the string.split() method to return the following list: ['Danish', 'krone']\n",
        "listwords = words.split()\n",
        "\n",
        "#Use the index -1 to return the last word of the list.\n",
        "listwords[-1]\n",
        "```\n",
        "\n",
        "Now, to repeat this task for each element in the Series, let's return to a concept we learned in the previous lesson - the [Series.apply()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.apply.html) method.\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "- Write a function called **extract_last_word** with the following criteria:\n",
        "  - The function should accept one parameter called **element**.\n",
        "  - Use the **string.split()** method to split the object into a list. First convert element to a string as follows: str(element).\n",
        "  - Return the last word of the list.\n",
        "- Use the **Series.apply()** method to apply the function to the **CurrencyUnit** column. Save the result to **merged['Currency Apply']**.\n",
        "- Use the **Series.head()** method to print the first five rows in **merged['Currency Apply']**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKXS-M6o82hy"
      },
      "source": [
        "# put your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wvNycurAWV9"
      },
      "source": [
        "### 1.3 Vectorized String Methods Overview\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ub0K5moAhgW"
      },
      "source": [
        "In the last exercise, we extracted the last word of each element in the **CurrencyUnit** column using the **Series.apply()** method. However, we also learned in the last lesson that we should use built-in vectorized methods (if they exist) instead of the **Series.apply()** method for performance reasons.\n",
        "\n",
        "Instead, we could've split each element in the **CurrencyUnit** column into a list of strings with the **Series.str.split()** method, the vectorized equivalent of Python's **string.split()** method:\n",
        "\n",
        "<left><img width=\"700\" src=\"https://drive.google.com/uc?export=view&id=1Pi_3aF47gQ0ZA2XOh0Z805_ws8BIuyux\"></left>\n",
        "\n",
        "\n",
        "In fact, pandas has built in a number of vectorized methods that perform the same operations for strings in series as Python string methods.\n",
        "\n",
        "Below are some common vectorized string methods, but you can find the full list [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html):\n",
        "\n",
        "| Method | Description |\n",
        "|----------------------|---------------------------------------------------------------|\n",
        "| Series.str.split() | Splits each element in the Series. |\n",
        "| Series.str.strip() | Strips whitespace from each string in the Series. |\n",
        "| Series.str.lower() | Converts strings in the Series to lowercase. |\n",
        "| Series.str.upper() | Converts strings in the Series to uppercase. |\n",
        "| Series.str.get() | Retrieves the ith element of each element in the Series. |\n",
        "| Series.str.replace() | Replaces a regex or string in the Series with another string. |\n",
        "| Series.str.cat() | Concatenates strings in a Series. |\n",
        "| Series.str.extract() | Extracts substrings from the Series matching a regex pattern. |\n",
        "\n",
        "\n",
        "We access these vectorized string methods by adding a **str** between the Series name and method name:\n",
        "\n",
        "<left><img width=\"300\" src=\"https://drive.google.com/uc?export=view&id=1WTHhIjNWsmB-P2wItoYYoJftuFKSA877\"></left>\n",
        "\n",
        "The **str** attribute indicates that each object in the Series should be treated as a string, without us having to explicitly change the type to a string like we did when using the **apply** method.\n",
        "\n",
        "Note that we can also slice each element in the Series to extract characters, but we'd still need to use the **str** attribute. For example, below we access the first five characters in each element of the **CurrencyUnit** column:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KohM18lcBKZ8",
        "outputId": "031c4750-52c6-4ae2-ce77-e1bae360694e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "merged['CurrencyUnit'].str[0:5].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Swiss\n",
              "1    Icela\n",
              "2    Danis\n",
              "3    Norwe\n",
              "4    Canad\n",
              "Name: CurrencyUnit, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kBSwFZZCRXx"
      },
      "source": [
        "It's also good to know that vectorized string methods can be **chained**. For example, suppose we needed to split each element in the **CurrencyUnit** column into a list of strings using the **Series.str.split()** method and capitalize the letters using the **Series.str.upper()** method. You can use the following syntax to apply more than one method at once:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pQO2jJ-CnPy",
        "outputId": "b23f8d7c-61cb-46b7-b870-591cd751a018",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "merged['CurrencyUnit'].str.upper().str.split().head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [SWISS, FRANC]\n",
              "1      [ICELAND, KRONA]\n",
              "2       [DANISH, KRONE]\n",
              "3    [NORWEGIAN, KRONE]\n",
              "4    [CANADIAN, DOLLAR]\n",
              "Name: CurrencyUnit, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLeXt1YJCqr6"
      },
      "source": [
        "However, don't forget to include **str** before each method name, or you'll get an error! Let's practice using vectorized string methods next.\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "- Use the **Series.str.split()** method to split the **CurrencyUnit** column into a list of words and then use the **Series.str.get()** method to select just the last word. Assign the result to **merged['Currency Vectorized']**.\n",
        "- Use the Series.head() method to print the first five rows in **merged['Currency Vectorized']**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTvlgtWADGu3"
      },
      "source": [
        "# put your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDvKwZ-aDRSf"
      },
      "source": [
        "### 1.4 Exploring Missing Values with Vectorized String Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu7bHp2uFaKO"
      },
      "source": [
        "We learned that using vectorized string methods results in:\n",
        "\n",
        "- Better performance\n",
        "- Code that is easier to read and write\n",
        "\n",
        "Let's explore another benefit of using vectorized string methods next. Suppose we wanted to compute the length of each string in the **CurrencyUnit** column. If we use the **Series.apply()** method, what happens to the missing values in the column?\n",
        "\n",
        "First, let's use the [Series.isnull()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.isnull.html) method to confirm if there are any missing values in the column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VOMUMsDG4tA",
        "outputId": "b86a25e9-b9e2-456a-bc9a-ec4c6e831e6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "merged['CurrencyUnit'].isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GXRg5PCG5a3"
      },
      "source": [
        "So, we know that the **CurrencyUnit** column has 13 missing values.\n",
        "\n",
        "Next, let's create a function to return the length of each currency unit and apply it to the **CurrencyUnit** column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5m8N3TTHYeN"
      },
      "source": [
        "def compute_lengths(element):\n",
        "    return len(str(element))\n",
        "lengths_apply = merged['CurrencyUnit'].apply(compute_lengths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAPuqEb9HbfB"
      },
      "source": [
        "Then, we can check the number of missing values in the result by setting the dropna parameter in the **Series.value_counts()** method to False:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4Z2oxGYHh7C",
        "outputId": "fb1925e7-ce76-4c95-81c0-9e2b74c55667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "lengths_apply.value_counts(dropna=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14    21\n",
              "4     20\n",
              "12    17\n",
              "13    14\n",
              "3     13\n",
              "15    13\n",
              "16    12\n",
              "18     9\n",
              "17     9\n",
              "11     8\n",
              "22     7\n",
              "25     5\n",
              "19     3\n",
              "9      2\n",
              "26     1\n",
              "20     1\n",
              "23     1\n",
              "10     1\n",
              "39     1\n",
              "Name: CurrencyUnit, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kt8568BxHkye"
      },
      "source": [
        "Since the original column had 13 missing values and **NaN** doesn't appear in the list of unique values above, we know our function must have treated **NaN** as a string and returned a length of 3 for each **NaN** value. This doesn't make sense - missing values shouldn't be treated as strings. They should instead have been excluded from the calculation.\n",
        "\n",
        "If we wanted to exclude missing values, we'd have to update our function to something like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InKDqUm-IGCn"
      },
      "source": [
        "def compute_lengths(element):\n",
        "    if pd.isnull(element):\n",
        "        pass\n",
        "    else:\n",
        "        return len(str(element))\n",
        "lengths_apply = merged['CurrencyUnit'].apply(compute_lengths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LnB9vVnIGjc"
      },
      "source": [
        "Let's confirm the behavior of pandas' vectorized string methods next.\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "- Use the **Series.str.len()** method to return the length of each element in the **CurrencyUnit** column. Assign the result to **lengths**.\n",
        "- Use the **Series.value_counts()** method to return the count of unique values in **lengths**. Set the dropna parameter to False so NaNs are counted, too. Assign the result to **value_counts**.\n",
        "  - If **value_counts** contains NaNs, it means the **Series.str.len()** method excluded them and didn't treat them as strings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buKZEw8rIKTq"
      },
      "source": [
        "# put your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q41dY3d9Iwg1"
      },
      "source": [
        "### 1.5  Finding Specific Words in Strings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb1IUcNaJVCY"
      },
      "source": [
        "In the last exercise, we identified a third benefit of using vectorized string methods - they exclude missing values:\n",
        "\n",
        "- Better performance\n",
        "- Code that is easier to read and write\n",
        "- Automatically excludes missing values\n",
        "\n",
        "Now that we know the benefits of using vectorized string methods, let's practice using them for specific data cleaning tasks.\n",
        "\n",
        "Suppose we needed to parse the elements of a Series to find a string or substring that doesn't appear in the same position in each string. For example, let's look at the **SpecialNotes** column. A number of rows mention **\"national accounts\"**, but the words appear in different places in each comment:\n",
        "\n",
        "```python\n",
        "April 2013 database update: Based on IMF data, national accounts data were revised for 2000 onward; the **base year** changed to 2002.\n",
        "Based on IMF data, national accounts data have been revised for 2005 onward; the new base year is 2005.\n",
        "```\n",
        "\n",
        "If we wanted to determine how many comments contain this phrase, could we split them into lists? Since the formats are different, how could we tell which element contains the \"national accounts\" phrase?\n",
        "\n",
        "We can handle problems like this with **regular expressions**, or **regex** for short. A regular expression is a sequence of characters that describes a search pattern, used to match characters in a string:\n",
        "\n",
        "<left><img width=\"300\" src=\"https://drive.google.com/uc?export=view&id=1MT28pLxiXEdGSiYBRmiw_Qtn4rZg9kzj\"></left>\n",
        "\n",
        "In pandas, regular expressions is integrated with vectorized string methods to make finding and extracting patterns of characters easier. However, the rules for creating regular expressions can be quite complex, so don't worry about memorizing them. In this mission, we'll provide guidance on how to create the regex we need to use for the exercises, but you can also follow along using this [documentation](https://docs.python.org/3.4/library/re.html).\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "\n",
        "We've already saved the regex to a variable called **pattern**. The brackets, [], indicate that either \"national accounts\" or \"National accounts\" should produce a match.\n",
        "\n",
        "- Use the [Series.str.contains()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.str.contains.html) method to search for pattern in the **SpecialNotes** column. Assign the result to **national_accounts**.\n",
        "- Use the **Series.head()** method to print the first five rows in **national_accounts**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsOFydUtMQyW"
      },
      "source": [
        "pattern = r\"[Nn]ational accounts\"\n",
        "\n",
        "# put your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymo7qTZlN0-j"
      },
      "source": [
        "### 1.6 Finding Specific Words in Strings Continued"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIAMe0mON75f"
      },
      "source": [
        "In the last section, we used the **Series.str.contains()** method to see if a specific phrase appeared in a series. The result was a series containing True, False, and missing values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HILLmlEPV0T",
        "outputId": "1403a6e9-8a6a-4d59-a360-2b5028e04025",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "national_accounts = merged['SpecialNotes'].str.contains(r\"[Nn]ational accounts\")\n",
        "\n",
        "#Return the value counts for each value in the Series, including missing values.\n",
        "national_accounts.value_counts(dropna=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NaN      65\n",
              "True     54\n",
              "False    39\n",
              "Name: SpecialNotes, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3ER6ydBPWZn"
      },
      "source": [
        "Now, we should be able to use boolean indexing to return only the rows that contain \"national accounts\" or \"National accounts\" in the **SpecialNotes** column:\n",
        "\n",
        "```python\n",
        "merged[national_accounts]\n",
        "...\n",
        "ValueError: cannot index with vector containing NA / NaN values\n",
        "```\n",
        "\n",
        "It looks like we got an error now because of the NaN values! One way we could fix this is to change the NaN values to False in **national_accounts**.\n",
        "\n",
        "<left><img width=\"300\" src=\"https://drive.google.com/uc?export=view&id=1OlbhaNyvRkiCsk56riPXZLUnK_5b54Sw\"></left>\n",
        "\n",
        "Let's practice a way we can easily make this change.\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "- Use the **Series.str.contains()** method to search for pattern in the **SpecialNotes** column again. This time, also pass in the **na** parameter and set it to False. Assign the result to **national_accounts**.\n",
        "- Use **national_accounts** to index **merged**, so that only rows that contain \"national accounts\" or \"National accounts\" in the **SpecialNotes** column are returned. Assign the result to **merged_national_accounts**.\n",
        "- Use the **DataFrame.head()** method to print the first five rows in **merged_national_accounts**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZIv5rtIPq3u"
      },
      "source": [
        "pattern = r\"[Nn]ational accounts\"\n",
        "\n",
        "# put your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOr36559RLqn"
      },
      "source": [
        "### 1.7 Extracting Substrings from a Series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrdKWTFbRiJO"
      },
      "source": [
        "In the last section, we learned how to use regular expressions and the **Series.str.contains()** method to search for patterns of characters in a column and index the dataframe based on the matches. Let's continue exploring the versatility of regular expressions while learning a new task - extracting characters from strings.\n",
        "\n",
        "Suppose we wanted to extract any year mentioned in the **SpecialNotes** column. Notice that the characters in a year follow a specific pattern:\n",
        "\n",
        "<left><img width=\"300\" src=\"https://drive.google.com/uc?export=view&id=1BYoOv80p-4mtNx06uZlwIsehGQOLwgbq\"></left>\n",
        "\n",
        "The first digit can be either 1 or 2, while the last three digits can be any number between 0 and 9.\n",
        "\n",
        "With regular expressions, we use the following syntax to indicate a character could be a range of numbers:\n",
        "\n",
        "```python\n",
        "pattern = r\"[0-9]\"\n",
        "```\n",
        "\n",
        "And we use the following syntax to indicate a character could be a range of letters:\n",
        "\n",
        "```python\n",
        "#lowercase letters\n",
        "pattern1 = r\"[a-z]\"\n",
        "\n",
        "#uppercase letters\n",
        "pattern2 = r\"[A-Z]\"\n",
        "```\n",
        "\n",
        "We could also make these ranges more restrictive. For example, if we wanted to find a three character substring in a column that starts with a number between 1 and 6 and ends with two letters of any kind, we could use the following syntax:\n",
        "\n",
        "```python\n",
        "pattern = r\"[1-6][a-z][a-z]\"\n",
        "```\n",
        "\n",
        "If we have a pattern that repeats, we can also use curly brackets { and } to indicate the number of times it repeats:\n",
        "\n",
        "```python\n",
        "pattern = r\"[1-6][a-z][a-z]\" = r\"[1-6][a-z]{2}\"\n",
        "```\n",
        "\n",
        "Let's use what we've learned to explore the [Series.str.extract()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.extract.html) method.\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "- Create a regular expression that will match years and assign it to the variable **pattern**. Note: we've already set up the pattern variable. Insert your answer inside the parantheses: \"(your_answer)\".\n",
        "- Use pattern and the **Series.str.extract()** method to extract years from the **SpecialNotes** column. Assign the resulting Series to **years**.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiFdugK2SeP0"
      },
      "source": [
        "pattern =r\"()\"\n",
        "\n",
        "# put your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0THDRJPsUWf_"
      },
      "source": [
        "### 1.8 Extracting Substrings from a Series Continued"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1HMvTHkVDUr"
      },
      "source": [
        "In the last exercise, we learned how to identify more complex patterns with regular expressions and extract substrings from a column using that pattern.\n",
        "\n",
        "When we used the **Series.str.extract()** method, we enclosed our regular expression in parentheses. The parentheses indicate that only the character pattern matched should be extracted and returned in a series. We call this a **capturing group**.\n",
        "\n",
        "<left><img width=\"300\" src=\"https://drive.google.com/uc?export=view&id=1I5agNs59zODQVzt_ORIKl02OpLsErRdC\"></left>\n",
        "\n",
        "If the capturing group doesn't exist in a row (or there is no match) the value in that row is set to NaN instead. As a result, the Series returned looked like this:\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=19llnxsXRC4XU98LyyzVJwDdShrVt22_q\"></left>\n",
        "\n",
        "We can also return the results as a dataframe by changing the expand parameter to True.\n",
        "\n",
        "Let's try that next.\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "\n",
        "- Use pattern and the **Series.str.extract()** method to extract years from the **SpecialNotes** column again, but this time, set the **expand** parameter to True to return the results as a dataframe. Assign the resulting dataframe to **years**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG8Dwt5dVhd-"
      },
      "source": [
        "pattern = r\"([1-2][0-9]{3})\"\n",
        "\n",
        "# put your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lifg_xnGXOFH"
      },
      "source": [
        "### 1.9 Extracting All Matches of a Pattern from a Series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCMtYtj7YO8E"
      },
      "source": [
        "In the last section, we learned we could use the **Series.str.extract()** method to extract a pattern of characters from a column as a dataframe by setting the expand parameter equal to True. However, the **Series.str.extract()** method will only extract the first match of the pattern. If we wanted to extract all of the matches, we can use the [Series.str.extractall()](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.extractall.html) method.\n",
        "\n",
        "We'll demonstrate this method but, first, let's make the results easier to read by using the [df.set_index()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.set_index.html) method to set the **Country** column as the index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moeDcSOgYtAN"
      },
      "source": [
        "merged = merged.set_index('Country')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCtBJ4d4YyCB"
      },
      "source": [
        "Next, let's use the same regular expression from the last section to extract all the years from the **SpecialNotes** column, except this time, we'll use a **named capturing group**. Using a named capturing group means that we can refer to the group by the specified name instead of just a number. We can use the following syntax to add a name: **(?P<Column_Name>...)**.\n",
        "\n",
        "Below, we name the capturing group **Years**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXIKfpNlZPMO",
        "outputId": "dd198c25-e242-45a0-9769-14c0b50dd3a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "pattern = r\"(?P<Years>[1-2][0-9]{3})\"\n",
        "merged['SpecialNotes'].str.extractall(pattern).head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Years</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Country</th>\n",
              "      <th>match</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"2\" valign=\"top\">Finland</th>\n",
              "      <th>0</th>\n",
              "      <td>1999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"3\" valign=\"top\">Netherlands</th>\n",
              "      <th>0</th>\n",
              "      <td>1999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Years\n",
              "Country     match      \n",
              "Finland     0      1999\n",
              "            1      1999\n",
              "Netherlands 0      1999\n",
              "            1      2037\n",
              "            2      1999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-ffwtDyaA0b"
      },
      "source": [
        "Below are the first five rows of the output:\n",
        "\n",
        "<left><img width=\"400\" src=\"https://drive.google.com/uc?export=view&id=1Fo531l4EzCQWxJqh6tyYfaIUEpOThHLq\"></left>\n",
        "\n",
        "Let's look at the **IESurvey** column next. This column has years in two different formats\n",
        "\n",
        "```python\n",
        "Integrated household survey (IHS), 2012\n",
        "Integrated household survey (IHS), 2010/11\n",
        "```\n",
        "\n",
        "Let's test the code above on this column to see if we can extract all of the years from the **IESurvey** column.\n",
        "\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "We've already set the **Country** column as the index and saved the regular expression used to extract years in the pattern variable.\n",
        "\n",
        "- Use the **Series.str.extractall()** method to extract all of the years in the **IESurvey**. Assign the result to **years**.\n",
        "- Use the **Series.value_counts()** method to create a list of the unique years, along with the count. Assign the result to **value_counts**. Print **value_counts**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCCKnEX1af2m"
      },
      "source": [
        "pattern = r\"(?P<Years>[1-2][0-9]{3})\"\n",
        "\n",
        "# put your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFxpHsCTcA4i"
      },
      "source": [
        "### 1.10 Extracting More Than One Group of Patterns from a Series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhM9hejS8_Sl"
      },
      "source": [
        "When we tried to extract all of the years from the **IESurvey** column using the **extractall** method in the last exercise, we were unsuccessful because some of our years had the following format:\n",
        "\n",
        "<left><img width=\"300\" src=\"https://drive.google.com/uc?export=view&id=19yh-bgjh6r465E_pA3gP9sqaBgIzBDxz\"></left>\n",
        "\n",
        "Because our regular expression only accounted for the pattern highlighted below, we created a dataframe with just the first year in each row:\n",
        "\n",
        "<left><img width=\"300\" src=\"https://drive.google.com/uc?export=view&id=1R6FGFeA9QXq9QhhwEklTjor5v9al0fL4\"></left>\n",
        "\n",
        "If we wanted to extract the second, abbreviated year, we'd have to specify two more groups - one to extract the / and one to extract the last two digits.\n",
        "\n",
        "<left><img width=\"300\" src=\"https://drive.google.com/uc?export=view&id=1rgY3QOPtVJgdfzHd480dRA8-M4q4sRSh\"></left>\n",
        "\n",
        "Let's add those two groups to our regex and try to extract them again:\n",
        "\n",
        "```python\n",
        "pattern = r\"(?P<First_Year>[1-2][0-9]{3})(/)?(?P<Second_Year>[0-9]{2})?\"\n",
        "years = merged['IESurvey'].str.extractall(pattern)\n",
        "```\n",
        "\n",
        "Note that we also added a question mark, ?, after each of the two new groups to indicate that a match for those groups is optional. This allows us to extract years listed in the **yyyy** format AND the **yyyy/yy** format at once.\n",
        "\n",
        "Below are the first five rows:\n",
        "\n",
        "<left><img width=\"300\" src=\"https://drive.google.com/uc?export=view&id=1_cg1lj6jYAM_uWok2yLr5PeKuDFGWNUu\"></left>\n",
        "\n",
        "If we sort the values, we can confirm that we also extracted years in the yyyy/yy format:\n",
        "\n",
        "```python\n",
        "years.sort_values('Second_Year')\n",
        "```\n",
        "\n",
        "<left><img width=\"300\" src=\"https://drive.google.com/uc?export=view&id=19p0t1-JKxsCvDWizn86nUEReN3wMTFph\"></left>\n",
        "\n",
        "The dataframe returned has three columns - one for each capturing group specified in pattern. Because we didn't name the second group, (/), the capturing group number, 1, was used as the column name.\n",
        "\n",
        "In the next exercise, we'll extract just the years from the **IESurvey** column. Then, we'll reformat the second year so that it contains all four digits of the year, not just the last two, so that it looks like the dataframe below:\n",
        "\n",
        "<left><img width=\"300\" src=\"https://drive.google.com/uc?export=view&id=1Xyo5f5EPaDt8yGqDbWN03scrB18IuLBQ\"></left>\n",
        "\n",
        "Let's complete this task next.\n",
        "\n",
        "\n",
        "**Exercise**\n",
        "\n",
        "<left><img width=\"100\" src=\"https://drive.google.com/uc?export=view&id=1E8tR7B9YYUXsU_rddJAyq0FrM0MSelxZ\"></left>\n",
        "\n",
        "We've already created a regular expression that extracts the pattern **\"yyyy/yy\"** and saved it to a variable called **pattern**. Notice that we didn't enclose **/?** in parantheses so that the resulting dataframe will only contain a **First_Year** and **Second_Year** column.\n",
        "\n",
        "- Use the **Series.str.extractall()** method to extract **pattern** from the **IESurvey** column. Assign the result to **years**.\n",
        "- Use vectorized slicing to extract the first two numbers from the **First_Year** column in **years** (For example, extract \"20\" from \"2000\"). Assign the result to **first_two_year**.\n",
        "- Add **first_two_year** to the **Second_Year** column in **years**, so that **Second_Year** contains the full year (ex: \"2000\"). Assign the result to **years['Second_Year']**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHIYTdhk9bwB"
      },
      "source": [
        "pattern = r\"(?P<First_Year>[1-2][0-9]{3})/?(?P<Second_Year>[0-9]{2})?\"\n",
        "\n",
        "# put your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8V9NcawnC95q"
      },
      "source": [
        "### 1.11 Next Steps\n",
        "\n",
        "Let's summarize what we learned about the **Series.str.extractall()** method and pandas string operations in the last exercise:\n",
        "\n",
        "- If part of the regex isn't grouped using parantheses, (), it won't be extracted.\n",
        "- When we add a string to a column using the plus sign, +, pandas will add that string to every value in the column. Note that the strings will be added together without any spaces.\n",
        "\n",
        "\n",
        "In this lesson, we explored the benefits of using vectorized string methods, along with a couple methods that can be used to perform tasks such as finding substrings, extracting substrings, and removing substrings from columns. You can find the full list of vectorized string methods [here](https://pandas.pydata.org/pandas-docs/stable/text.html#method-summary). We encourage you to explore more string methods or string cleaning tasks independently.\n",
        "\n",
        "In the next lesson, we'll go deeper in data cleaning task in order to explore regex in more details."
      ]
    }
  ]
}